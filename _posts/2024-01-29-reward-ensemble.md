---
title: Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble (Short Paper)
image: images/reward-ensemble.png
categories: preprint
tags: [large language model, value alignment]
venue: arXiv
year: 2024
authors: [Shun Zhang, Zhenfang Chen, Sunli Chen, Yikang Shen, Zhiqing Sun, Chuang Gan]
paper: https://arxiv.org/pdf/2401.16635.pdf
slides: 
website: 
code: 
---
We introduce efficient reward model ensemble approaches for reinforcement learning from human feedback (RLHF),
achieving better alignment with human values under computational constraints.
